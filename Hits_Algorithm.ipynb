{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot run multiple SparkContexts at once; existing SparkContext(app=pyspark-shell, master=local[*]) created by __init__ at <ipython-input-1-ccf36d563afa>:8 ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-ccf36d563afa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0msc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# rdd = sc.parallelize([(\"a\", 1)])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\spark\\spark-2.4.3-bin-hadoop2.7\\python\\pyspark\\context.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\u001b[0m\n\u001b[0;32m    131\u001b[0m                     \" note this option will be removed in Spark 3.0\")\n\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m         \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgateway\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgateway\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    134\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m             self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n",
      "\u001b[1;32mC:\\spark\\spark-2.4.3-bin-hadoop2.7\\python\\pyspark\\context.py\u001b[0m in \u001b[0;36m_ensure_initialized\u001b[1;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[0;32m    330\u001b[0m                         \u001b[1;34m\" created by %s at %s:%s \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m                         % (currentAppName, currentMaster,\n\u001b[1;32m--> 332\u001b[1;33m                             callsite.function, callsite.file, callsite.linenum))\n\u001b[0m\u001b[0;32m    333\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m                     \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minstance\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot run multiple SparkContexts at once; existing SparkContext(app=pyspark-shell, master=local[*]) created by __init__ at <ipython-input-1-ccf36d563afa>:8 "
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "# SQLContext or HiveContext in Spark 1.x\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "\n",
    "sc = SparkContext()\n",
    "\n",
    "# rdd = sc.parallelize([(\"a\", 1)])\n",
    "# hasattr(rdd, \"toDF\")\n",
    "# ## False\n",
    "\n",
    "spark = SparkSession(sc)\n",
    "# hasattr(rdd, \"toDF\")\n",
    "# ## True\n",
    "\n",
    "# rdd.toDF().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pyspark.pyspark.mllib.linalg import Matrix, Matrices\n",
    "from pyspark.mllib.linalg.distributed import BlockMatrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_ids = spark.read.format(\"csv\").option(\"inferSchema\", \"true\") \\\n",
    ".option(\"header\", \"true\") \\\n",
    ".option(\"delimiter\", \" \") \\\n",
    ".load(r\"C:\\Users\\uschlac\\Documents\\Spark_Practice\\Dataset\\links.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_ids.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connenctions = spark.read.format(\"csv\").option(\"inferSchema\", \"true\") \\\n",
    ".option(\"header\", \"true\") \\\n",
    ".option(\"delimiter\", \" \") \\\n",
    ".load(r\"C:\\Users\\uschlac\\Documents\\Spark_Practice\\Dataset\\hollins.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authority Weights Vector:\n",
    "# v = (A)t * u\n",
    "# Assuming inital hub weight (u) is one.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename=r'hits.png') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In the above image we have three individual web pages labeled (1, 2, and 3).\n",
    "\n",
    "### From the initial view, we can see that Nodes: 1 and 2 are Hub Nodes (web pages that lead to others) and that Node: 3 is an Authority Node (Web Page that is the final destination).\n",
    "\n",
    "### Matrix Structure\n",
    "\n",
    "| Node Label | Ends at 1 | Ends at 2 | Ends at 3 |\n",
    "| --- | --- | --- | --- |\n",
    "| Starts at 1 | 0 | 0 | 1 |\n",
    "| Starts at 2 | 0 | 0 | 1 |\n",
    "| Starts at 3 | 0 | 0 | 0 |\n",
    "\n",
    "### Adjacency  Matrix in Spark:\n",
    "\n",
    "$$A = \\begin{bmatrix} 0 & 0 & 1 \\\\ 0 & 0 & 1 \\\\ 0 & 0 & 0 \\end{bmatrix}$$\n",
    "\n",
    "\n",
    "### Authority Weight Calculation:\n",
    "\n",
    "$$v = A^T \\cdot u = \\begin{bmatrix} 0 & 0 & 0 \\\\ 0 & 0 & 0 \\\\ 1 & 1 & 0 \\end{bmatrix} \\cdot \\begin{bmatrix} 1 \\\\ 1 \\\\ 1 \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 2 \\\\ 2 \\end{bmatrix} $$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Hub Weight Calculation:\n",
    "$$u = A \\cdot v = \\begin{bmatrix} 0 & 0 & 1 \\\\ 0 & 0 & 1 \\\\ 0 & 0 & 0 \\end{bmatrix} \\cdot \\begin{bmatrix} 0 \\\\ 0 \\\\ 2 \\end{bmatrix} = \\begin{bmatrix} 2 \\\\ 2 \\\\ 0 \\end{bmatrix} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation in Pyspark:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inital Hub Weights: \n",
      "DenseMatrix([[1.],\n",
      "             [1.],\n",
      "             [1.]])\n",
      "\n",
      "\n",
      "Authority Weights: \n",
      "DenseMatrix([[0.],\n",
      "             [0.],\n",
      "             [2.]])\n",
      "\n",
      "\n",
      "Updated Hub Weights: \n",
      "DenseMatrix([[2.],\n",
      "             [2.],\n",
      "             [0.]])\n"
     ]
    }
   ],
   "source": [
    "# Adjacency Matrix:\n",
    "dm_1 = Matrices.dense(3, 3, [0,0,0,0,0,0,1,1,0])\n",
    "blocks_1 = sc.parallelize([((0, 0), dm_1)])\n",
    "mat_1 = BlockMatrix(blocks_1, 3, 3)\n",
    "\n",
    "# Initial Hub Weights:\n",
    "weights = Matrices.dense(3, 1, [1,1,1])\n",
    "weight_block = sc.parallelize([((0, 0), weights)])\n",
    "weight_block = BlockMatrix(weight_block, 3, 1)\n",
    "print(\"Inital Hub Weights: \" + \"\\n\" + str(weight_block.toLocalMatrix()))\n",
    "\n",
    "#Authority Blocks:\n",
    "print(\"\\n\")\n",
    "authority_weight = mat_1.transpose().multiply(weight_block)\n",
    "print(\"Authority Weights: \" + \"\\n\" + str(authority_weight.toLocalMatrix()))\n",
    "print(\"\\n\")\n",
    "\n",
    "# Updated Hub Weights:\n",
    "hub_weight = mat_1.multiply(authority_weight)\n",
    "print(\"Updated Hub Weights: \" + \"\\n\" + str(hub_weight.toLocalMatrix()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Implementation:\n",
    "\n",
    "## The Dataset I am using for this Analysis is from Hollins University Website. This dataset contains information on the webmap of their website. This includes which webpages are linked to others.\n",
    "\n",
    "## The Dataset can be found on my github or at this link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.limfinity.com/ir/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+\n",
      "|start|end|\n",
      "+-----+---+\n",
      "|    1|  2|\n",
      "|    8|  2|\n",
      "|   16|  2|\n",
      "|   18|  2|\n",
      "|   20|  2|\n",
      "|    1|  3|\n",
      "|    1|  4|\n",
      "|    1|  5|\n",
      "|    1|  6|\n",
      "|    1|  7|\n",
      "|    4|  7|\n",
      "|    5|  7|\n",
      "|    8|  7|\n",
      "|    9|  7|\n",
      "|   11|  7|\n",
      "|   13|  7|\n",
      "|   15|  7|\n",
      "|   19|  7|\n",
      "|    1|  8|\n",
      "|    1|  9|\n",
      "+-----+---+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-----+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+\n",
      "|start|  2|  3|  4|  5|  6|  7|  8|  9| 10| 11| 12| 13| 14| 15| 16| 17| 18| 19| 20|\n",
      "+-----+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+\n",
      "|    1|  1|  1|  1|  1|  1|  1|  1|  1|  1|  1|  1|  1|  1|  1|  1|  1|  1|  1|  1|\n",
      "|    4|  0|  0|  0|  0|  0|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|  0|\n",
      "|    5|  0|  0|  0|  0|  0|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|  0|\n",
      "|    7|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|  0|\n",
      "|    8|  1|  0|  0|  0|  0|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|  0|\n",
      "|    9|  0|  0|  0|  0|  0|  1|  0|  0|  1|  0|  0|  0|  0|  1|  0|  0|  0|  1|  0|\n",
      "|   11|  0|  0|  0|  0|  0|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|  0|\n",
      "|   13|  0|  0|  0|  0|  0|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|  0|\n",
      "|   15|  0|  0|  0|  0|  0|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  1|  0|\n",
      "|   16|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|\n",
      "|   18|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|\n",
      "|   19|  0|  0|  0|  0|  0|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|\n",
      "|   20|  1|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|\n",
      "+-----+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "b = connenctions.filter(connenctions.start.between(0,20) & connenctions.end.between(0,20))\n",
    "b.show()\n",
    "mat_sample = b.groupBy(\"start\").pivot(\"end\").agg(F.lit(1)).na.fill(0).sort(F.col(\"start\").asc())\n",
    "mat_sample.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row Count: 13\n",
      "Column Count: 19\n"
     ]
    }
   ],
   "source": [
    "row_count = mat_sample.select(mat_sample.columns[1:]).count()\n",
    "print(\"Row Count: \" + str(row_count))\n",
    "col_count = len(mat_sample.select(mat_sample.columns[1:]).columns)\n",
    "print(\"Column Count: \" + str(col_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjacency Matrix:\n",
    "sample_matrix = Matrices.dense(row_count, col_count, np.array(mat_sample.select(mat_sample.columns[1:]).collect()).flatten())\n",
    "sample_block = sc.parallelize([((0, 0), sample_matrix)])\n",
    "sample_block_matrix = BlockMatrix(sample_block, row_count, col_count)\n",
    "\n",
    "# Initial Hub Weight Vector:\n",
    "weights = Matrices.dense(row_count, 1, np.repeat(1, row_count))\n",
    "weight_block = sc.parallelize([((0, 0), weights)])\n",
    "weight_block = BlockMatrix(weight_block, row_count, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenseMatrix([[13.],\n",
      "             [ 7.],\n",
      "             [ 1.],\n",
      "             [ 1.],\n",
      "             [ 1.],\n",
      "             [ 2.],\n",
      "             [ 1.],\n",
      "             [ 3.],\n",
      "             [ 2.],\n",
      "             [ 1.],\n",
      "             [ 2.],\n",
      "             [ 1.],\n",
      "             [ 1.],\n",
      "             [ 2.],\n",
      "             [ 1.],\n",
      "             [ 0.],\n",
      "             [ 1.],\n",
      "             [ 1.],\n",
      "             [ 0.]])\n"
     ]
    }
   ],
   "source": [
    "#Authority Blocks:\n",
    "print(sample_block_matrix.transpose().multiply(weight_block).toLocalMatrix())\n",
    "\n",
    "authority_weight = sample_block_matrix.transpose().multiply(weight_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenseMatrix([[22.],\n",
      "             [23.],\n",
      "             [26.],\n",
      "             [22.],\n",
      "             [23.],\n",
      "             [20.],\n",
      "             [14.],\n",
      "             [15.],\n",
      "             [18.],\n",
      "             [18.],\n",
      "             [14.],\n",
      "             [22.],\n",
      "             [16.]])\n"
     ]
    }
   ],
   "source": [
    "# Hub Weights:\n",
    "print(sample_block_matrix.multiply(authority_weight).toLocalMatrix())\n",
    "\n",
    "hub_weight = sample_block_matrix.multiply(authority_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "createDataFrame() missing 1 required positional argument: 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-f98fb3266eea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreateDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: createDataFrame() missing 1 required positional argument: 'data'"
     ]
    }
   ],
   "source": [
    "spark.createDataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hub_weight.rowsPerBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connenctions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = connenctions.groupBy(\"start\").pivot(\"end\").agg(F.lit(1)).na.fill(0).sort(F.col(\"start\").asc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
